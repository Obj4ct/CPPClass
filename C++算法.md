# 算法

## 什么是算法
算法是指解决问题或执行任务的明确定义的步骤序列。这些步骤通常是有限的、指令清晰的，并且可以按顺序执行，以达到特定的结果。

算法的几个关键特性包括：

**输入：算法通常需要零个或多个输入。**

**输出：算法会产生一个或多个输出。**

**明确性：算法中的每一步都必须是精确且无歧义的。**

**有限性：算法必须在有限的步骤内完成，不能无限循环。**

**有效性：算法中的每一步都必须是可执行的，并且可以在有限的时间内完成。**

算法在计算机科学中无处不在，从简单的数学计算到复杂的数据处理和人工智能，都离不开算法。

### 算法的稳定性：

算法稳定性（Stability）是衡量排序算法性能的一个重要指标。

**定义：** 一个排序算法被称为是**稳定**的，如果它能保证在排序前和排序后，相等元素的**相对位置保持不变**。

换句话说，如果一个待排序的序列中有两个值相等的元素 `A` 和 `B`，并且在原始序列中 `A` 在 `B` 的前面，那么在排序后的序列中，`A` 仍然在 `B` 的前面。

如果排序算法无法保证这一点，那么它就是**不稳定**的。

**举例说明**

假设我们有一个包含自定义对象的列表，每个对象都有两个属性：`value` 和 `index`。我们希望根据 `value` 进行排序。

原始序列：`[(value: 5, index: 1), (value: 3, index: 2), (value: 5, index: 3)]`

这里有两个 `value` 都是 5 的元素。在原始序列中，`(value: 5, index: 1)` 在 `(value: 5, index: 3)` 的前面。

**稳定排序算法**的排序结果： `[(value: 3, index: 2), (value: 5, index: 1), (value: 5, index: 3)]`

- `value` 为 3 的元素被排到了前面。
- 两个 `value` 为 5 的元素，`(value: 5, index: 1)` 仍然在 `(value: 5, index: 3)` 的前面，相对位置没有改变。

**不稳定排序算法**的排序结果可能如下： `[(value: 3, index: 2), (value: 5, index: 3), (value: 5, index: 1)]`

- 两个 `value` 为 5 的元素，`(value: 5, index: 1)` 和 `(value: 5, index: 3)` 的相对位置发生了改变。

**为什么算法稳定性很重要？**

在对基本数据类型（如 `int`, `char` 等）进行排序时，稳定性可能不是一个大问题。但当排序的对象是包含多个属性的复杂数据结构时，稳定性就显得尤为重要。

例如，在数据库中，我们可能需要先按部门对员工进行排序，然后再按年龄对员工进行排序。

1. 首先，按部门排序，使用一个**稳定**的排序算法。此时，同一部门内的员工会保持原始的顺序。
2. 接着，再按年龄排序。如果这个排序算法也是**稳定**的，那么排序后，年龄相同的员工在序列中的相对位置（即他们原来的部门内顺序）就不会被破坏。
3. 如果第二次排序使用的是**不稳定**的算法，那么即使年龄相同，员工的相对顺序也可能被打乱，导致之前的排序结果被破坏。

**常见的稳定和不稳定排序算法**

**稳定的排序算法：**

- **冒泡排序 (Bubble Sort)**
- **插入排序 (Insertion Sort)**
- **归并排序 (Merge Sort)**
- **计数排序 (Counting Sort)**
- **基数排序 (Radix Sort)**

**不稳定的排序算法：**

- **选择排序 (Selection Sort)**
- **快速排序 (Quick Sort)**
- **堆排序 (Heap Sort)**
- **希尔排序 (Shell Sort)**

需要注意的是，某些不稳定的排序算法（如快速排序）可以通过一些技巧实现为稳定版本，但通常会牺牲一些性能。因此，我们通常讨论的是它们的**经典实现**的稳定性。



### 自然语言描述

自然语言描述算法，顾名思义，就是**使用日常语言（如中文、英文等）来描述一个算法的步骤和逻辑**。它不依赖于任何编程语言的语法或特定的符号，旨在让任何有基本逻辑思维能力的人都能理解算法的核心思想。

**特点和用途**

1. **易于理解和沟通**：这是自然语言描述最大的优势。非技术人员也能通过这种方式理解算法的工作原理，这在跨部门协作或向客户解释技术方案时非常有用。
2. **不精确性**：自然语言天生具有模糊性和歧义性。一个词语可能有多种解释，一个步骤的执行细节也可能不明确。因此，它通常用于描述算法的**宏观逻辑**，而非微观实现。
3. **缺乏结构**：与伪代码或编程语言不同，自然语言描述缺乏统一的结构，如循环、条件判断等。这使得描述复杂的、嵌套的逻辑时可能会显得冗长和混乱。
4. **适用于初级阶段**：在算法设计的早期阶段，程序员通常会先用自然语言来构思和记录想法，然后再逐步细化成伪代码，最后编写成实际代码。

**示例**

我们以“冒泡排序”为例，用自然语言来描述它的算法：

> **冒泡排序的自然语言描述：**
>
> 1. 从数组的第一个元素开始，依次向后遍历。
> 2. 在遍历过程中，比较相邻的两个元素。
> 3. 如果它们的大小顺序不符合要求（例如，从小到大排序时，前一个比后一个大），就交换它们的位置。
> 4. 重复这个过程，直到遍历到数组的末尾。这样，数组中最大（或最小）的元素就会被移动到最后的位置。
> 5. 忽略已经排好序的最后一个元素，对剩余的数组重复以上步骤。
> 6. 持续进行这个过程，直到数组的所有元素都处于正确的排序位置。

**对比**

- **自然语言描述 vs. 伪代码**：
  - **自然语言**更偏向于**高层次的概念**，缺乏结构和精确性。
  - **伪代码**则在自然语言的基础上加入了**结构化的编程概念**（如循环、条件判断），更加精确，但又没有严格的语法。
  - 因此，伪代码是自然语言描述和实际代码之间的一个很好的桥梁。
- **自然语言描述 vs. C++ 代码**：
  - **C++ 代码**是**完全精确**的，严格遵循语法规则，可以被编译器执行。
  - **自然语言描述**则无法直接执行，只能作为一种思想或逻辑的表达方式。

在日常学习和工作中，我们通常会混合使用这三种方式：先用自然语言描述算法的宏观思想，然后用伪代码细化逻辑，最后用 C++ 等编程语言实现。



### 伪代码

伪代码（Pseudocode）是一种非正式的、类似于编程语言的文本描述，用于描述算法或程序的工作原理。

**主要特点：**

- **非正式语法**：它没有严格的语法规则，不属于任何特定的编程语言。
- **易于理解**：它通常使用自然语言（如英语或中文）和一些编程语言的结构化约定（如 `if-then-else`, `for-loop`, `while`）相结合，使得非程序员也能理解。
- **专注于逻辑**：伪代码的重点是表达算法的**逻辑和步骤**，而不是具体的实现细节（如变量类型声明、内存管理、特定的函数调用语法等）。
- **平台无关**：因为它不是真正的代码，所以可以在任何编程语言或平台上实现。

**为什么使用伪代码？**

1. **设计和规划**：在编写实际代码之前，程序员可以使用伪代码来规划算法的逻辑。这有助于理清思路，发现潜在的问题，并与其他开发者沟通设计方案。
2. **教学和学习**：在计算机科学教育中，伪代码常用于向学生解释复杂的算法，因为它消除了编程语言特有语法的障碍，让学生能专注于算法的核心思想。
3. **代码原型**：它可以作为实际代码的“草稿”，程序员可以先用伪代码勾勒出主要逻辑，然后再将其逐步翻译成具体的编程语言代码。
4. **清晰表达**：对于复杂的算法，伪代码比纯粹的自然语言描述更结构化，比实际代码更易于阅读和理解。

```cpp
// 冒泡排序
function bubbleSort(array A):
    n = length(A)
    for i from 0 to n-1:
        swapped = false
        for j from 0 to n-i-1:
            if A[j] > A[j+1]:
                swap(A[j], A[j+1])
                swapped = true
        if swapped is false:
            break
    return A
```

- `function bubbleSort(array A):`：使用了函数和参数的概念。
- `n = length(A)`：使用了变量赋值和获取长度的操作，但没有严格的语法。
- `for ... to ...:`：使用了循环结构。
- `if ...:`：使用了条件判断。
- `swap(A[j], A[j+1])`：使用了函数调用，但没有详细说明如何实现交换。
- `return A`：使用了返回值。

这段伪代码清晰地表达了冒泡排序的逻辑：两层循环，内层循环比较并交换相邻元素，如果一轮没有交换则提前退出。



### 流程图

[用流程图描述算法 - 知乎](https://zhuanlan.zhihu.com/p/39625195)

## 1. 模拟法

### 1.1 什么是模拟法

模拟法，顾名思义，是一种通过**模拟真实系统或过程**来研究其行为和性能的方法。

它不直接对系统进行数学分析，而是尝试**重现系统随时间演变的过程**，从而观察和收集数据，进而推断系统的特性。

**核心思想**

模拟法的核心是建立一个模型，这个模型能够模仿或表示真实世界系统中的关键元素、关系和动态行为。然后，通过运行这个模型，观察其在不同条件下的响应，从而获得对真实系统的理解。

### 1.2 模拟法的主要特点

**主要特点：**

1. **动态性：** 模拟法通常关注系统随时间变化的动态行为，而非仅仅静态的属性。
2. **实验性：** 它类似于在计算机上进行实验。通过改变模型中的参数或输入条件，可以观察系统行为的变化。
3. **复杂系统适用性：** 对于那些过于复杂，难以用解析（数学公式）方法求解的系统，模拟法是特别有用的工具。
4. **预测性：** 模拟可以用来预测系统在未来或不同操作条件下的表现。
5. **试错成本低：** 在计算机模型上进行模拟，比在真实系统中进行实验的成本要低得多，风险也小得多。

**例如**

飞行器的运动轨迹模拟、流体力学模拟、电力系统负荷变化模拟

### 1.3 模拟的基本流程

**定义问题：** 明确要解决的问题和模拟的目标。

**系统分析：** 识别系统边界、关键组件、变量和它们之间的关系。

**模型建立：** 将系统逻辑转化为计算机模型，包括：

- 确定系统状态变量。
- 定义事件和事件发生条件。
- 指定随机变量的概率分布。
- 制定时间推进机制。

**数据收集与输入：** 收集系统运行所需的历史数据、参数和随机数。

**模型验证与确认：** 确保模型能够准确反映真实系统，并能够解决最初定义的问题。

- **验证 (Verification)：** 检查模型是否按照设计意图正确实现（模型是否正确）。
- **确认 (Validation)：** 检查模型输出是否与真实系统行为一致（模型是否有效）。

**实验设计：** 确定需要运行的模拟次数、每次模拟的长度以及要改变的参数。

**模拟运行：** 执行计算机程序，收集模拟数据。

**结果分析与解释：** 对模拟输出数据进行统计分析，提取有意义的结论，并据此做出决策。

### 1.4 模拟法的适用场景

系统过于复杂，无法进行解析分析。

在真实系统上进行实验成本过高或风险太大。

需要预测系统在不同条件下的未来表现。

用于系统设计和优化，评估不同方案的效果。

研究系统对随机输入或扰动的响应。

### 1.5 例子

*这是一口很深的井（相对于青蛙而言），井壁由m块圆环形的砖头构成，每块砖头的高度都是p，青蛙每天白天最多能够向上爬的高度是q。* 

 *但是，很不幸的是，晚上砖头会渗水，会变得很滑，如果青蛙不能藏在两块砖头之间，那么青蛙将会滑落回井底。* 

 *还好青蛙是公主变的，还保留了公主的智商，在确定当天无法爬出井口的情况下，会选择白天结束前躲在尽可能高的砖缝之间，避免晚上跌落。* 

 *问：青蛙要花几天才能爬出来。* 

 *输入描述* 

 *一个正整数n，表示案例的数量。* 

 *每组案例由三个正整数m、p、q组成。(m<=5000, p<=1000, q<=1000)* 

 *输出描述* 

 *针对每组案例，输出一个整数，表示爬出来需要的天数。如果无法爬出来，则输出-1。* 

 *样例输入* 

 *2* 

 *5 2 3* 

 *5 3 2* 

 *样例输出* 

 *5* 

 *-1*

```cpp
#include <iostream>

int main() 
{
    int n; // 案例数量
    std::cin >> n;

    while (n--)
    {
        long long m, p, q; // 使用 long long 防止 m*p 溢出
        std::cin >> m >> p >> q;

        long long total_depth = m * p; // 井的总深度
        long long current_height = 0;  // 青蛙当前高度
        int days = 0;                  // 天数

        // 特殊情况：如果青蛙每天爬的高度 q 小于一块砖的高度 p，
        if (q < p ) 
        { 
            std::cout << -1 << std::endl;
            continue; // 处理下一个案例
        }
        
        // 另一种特殊情况：如果井深为0，或者q本身就能一步出井（即使q<p，但如果井就那么深）
        // 比如 m=1, p=10, q=5。total_depth=10。q<p但是青蛙只需要爬10就可以出井，5+5...
        // 应该考虑的是青蛙是否能一次性爬到total_depth。
        // 如果 q >= total_depth，青蛙第一天就能出去，除非total_depth是0 (m=0)
        if (total_depth == 0) // 井是空的，0天
        { 
             std::cout << 0 << std::endl;
             continue;
        }

        while (true)
        {
            days++; // 天数增加

            // 白天爬升
            current_height += q;

            // 判断是否出井
            if (current_height >= total_depth) 
            {
                std::cout << days << std::endl;
                break; // 青蛙已爬出
            }

            // 晚上处理：如果未出井，躲到尽可能高的砖缝
            // 由于青蛙会滑回井底的条件是“不能藏在两块砖头之间”，
            // 且它会“选择白天结束前躲在尽可能高的砖缝之间”，
            // 这意味着青蛙能安全过夜的高度必须是 p 的整数倍。
            // 并且，如果它爬不到第一块砖头的高度 p，它就会掉回井底。
            // 所以，如果 current_height < p，它当晚就会回到0。
            // 如果 current_height >= p，它会停留在 (current_height / p) * p 的位置。
            if (current_height < p) 
            {
                 // 如果白天爬了 q，但是连一块砖的高度都够不上，
                 // 且之前不是在井口，那么它当天晚上会滑回井底。
                 // 这种情况意味着永远无法爬出。
                 // 这个条件已经在循环前 if (q < p && m > 0) 覆盖了
                 // 理论上如果 q >= p，则 current_height 至少会是 p
                 // 所以这里可以不用特别处理 current_height = 0 的情况
                 std::cout << -1 << std::endl; // 此时意味着无法爬上第一块砖，永远出不来
                 break;
            } 
            else 
            {
                current_height = (current_height / p) * p; // 青蛙停留在能过夜的最高砖缝
            }
             
            // 检查是否陷入无限循环（例如，每次爬升后，晚上都会滑回同样的高度，无法进步）
            // 如果 current_height 在某次迭代结束后没有增长，并且还没出井，则陷入死循环
            // 考虑到如果 q < p，已经在前面处理了 -1 的情况
            // 如果 q >= p，那么每次 current_height 至少能增加 q - (q % p)
            // 每次循环至少有 progress >= p
            // 实际上，如果青蛙能爬过一块砖的高度，它就总能进步
            // 所以陷入死循环的唯一情况是 q < p，这已经在前面处理。
            // 这里不需要额外的死循环判断
        }
    }

    return 0;
}
```

通过程序一步步地重现了青蛙每天爬井的整个过程，直到达到最终条件（爬出井口或确定无法爬出）



## 2.二分查找

### 2.1 什么是二分查找

二分查找（Binary Search）又叫折半查找，是一种高效的查找算法，它主要用于在**已排序的**数据集合中查找特定元素的位置。它的核心思想是每次将查找范围缩小一半。

![image-20250708154936737](C:\Users\zthen\AppData\Roaming\Typora\typora-user-images\image-20250708154936737.png)

### 2.2 二分查找前提

#### 1.已排序

要进行二分查找的数据集合**必须是已排序的**（升序或降序均可）。如果数据未排序，二分查找将无法正确工作。

例如

1 2 3 4 5 6 7

7 6 5 4 3 2 1

不能是

1 3 2 4 6 5 7 

#### 2. 必须是顺序存储结构 

顺序存储结构（Sequential Storage Structure）是计算机内存中一种基本的数据存储方式。它的核心思想是：**将数据元素存储在一组地址连续的存储单元中。**

简单来说，如果你的数据是按照顺序存储的，那么在内存中它们也是一个接一个地紧密排列着。这种存储方式使得数据元素在逻辑上的相邻关系，在物理存储上也得以体现。

**物理地址连续：** 这是顺序存储结构最显著的特征。所有数据元素在内存中是紧密相连的，形成一个连续的内存块。

**随机访问（Random Access）：** 由于元素在内存中是连续的，并且每个元素的大小通常是固定的，你可以通过一个简单的数学公式，根据元素的索引（下标）直接计算出任何一个元素的内存地址。这使得访问任何一个元素的时间复杂度都是 O(1)，也就是说，访问第一个元素和访问第一百个元素所花费的时间是相同的。

- 例如，在一个整数数组中，如果知道第一个整数的地址和每个整数占用的字节数，那么第 `i` 个整数的地址可以立即计算出来。

**存储密度高：** 除了数据本身，不需要额外的存储空间来维护元素之间的逻辑关系（比如链表需要额外的指针来指向下一个元素）。

**插入和删除效率低：** 这是顺序存储结构的主要缺点。

- 如果在中间位置插入一个新元素，为了保持所有元素的连续性，需要将该位置之后的所有元素向后移动一个位置，以腾出空间。
- 如果在中间位置删除一个元素，同样需要将该位置之后的所有元素向前移动一个位置，以填补空缺。
- 这些移动操作的时间复杂度通常是 O(n)，其中 `n` 是需要移动的元素数量。
- 但在末尾进行插入和删除操作效率较高，通常是 O(1)。

**大小通常固定或需要扩容：** 典型的顺序存储结构（如C++中的静态数组）在创建时就需要指定大小。如果需要动态调整大小，通常涉及重新分配一个更大的内存块，然后将所有旧数据复制到新内存中，这会带来额外的开销。



**典型的实现：**

- **数组 (Array)：** 这是最经典、最常用的顺序存储结构。无论是 C++ 中的基本数组 `int arr[10];`，还是标准库中的 `std::vector`（虽然它在逻辑上是动态的，但其底层实现仍然是连续的内存块），都属于顺序存储。

**总结：**

顺序存储结构因其快速的随机访问特性而非常高效，特别适合那些需要频繁通过索引来访问数据，并且数据量相对稳定，或者对插入/删除操作不那么频繁的场景。但对于需要频繁进行中间插入和删除操作的场景，其性能可能会受到限制。

### 2.3 算法思想

**确定查找范围：** 首先，算法会确定一个查找范围，通常是整个数据集合。

**比较中间元素：** 将要查找的目标值与当前查找范围的**中间元素**进行比较。

- **如果目标值等于中间元素：** 查找成功，算法返回中间元素的位置。
- **如果目标值小于中间元素：** 说明目标值可能位于中间元素的左侧，因此查找范围缩小到中间元素的左半部分。
- **如果目标值大于中间元素：** 说明目标值可能位于中间元素的右侧，因此查找范围缩小到中间元素的右半部分。

**重复过程：** 算法会在新的查找范围内重复上述步骤，直到找到目标元素，或者查找范围变为空（这表示目标元素不存在于数据集合中）。

### 2.4 算法的时间复杂度

二分查找的效率非常高。每次比较都会将查找范围缩小一半。因此，对于大小为 N 的数据集合，二分查找的**时间复杂度是 O(logN)**。这意味着即使数据量非常大，查找所需的时间也只会以对数的速度增长，非常高效。

### 2.5 流程

例如在1-100中查找56

![image-20250708155352234](C:\Users\zthen\AppData\Roaming\Typora\typora-user-images\image-20250708155352234.png)

```cpp
#include <iostream> // 用于输入输出

int main() 
{
    int target_value; // 使用局部变量来存储要查找的目标值
    std::cout << "请输入一个1到100之间的整数进行查找: ";
    std::cin >> target_value; // 读取要查找的目标值

    int low = 1;  // 查找范围的左边界（值本身）
    int high = 100; // 查找范围的右边界（值本身）
    bool found = false; // 标记是否找到

    // 当 low <= high 时，表示查找范围有效
    while (low <= high) 
    {
        int mid = low + (high - low) / 2; // 计算中间值，防止溢出

        if (mid == target_value)
        { // 找到了目标值
            std::cout << "成功找到！目标值是: " << mid << std::endl;
            found = true;
            break; // 找到后立即退出循环
        } 
        else if (mid < target_value) 
        { // 中间值比目标值小，目标在右半部分
            low = mid + 1; // 缩小左边界
        } 
        else 
        { // mid > target_value，中间值比目标值大，目标在左半部分
            high = mid - 1; // 缩小右边界
        }
    }

    if (!found) 
    { // 如果循环结束还没找到
        std::cout << "查找失败！目标值 " << target_value << " 不在 1 到 100 的范围内或未找到。" << std::endl;
    }

    return 0;
}
```



## 3.分治算法

### 3.1 什么是分治算法

分治算法（Divide and Conquer Algorithm）是一种重要的算法设计策略。它的核心思想是将一个难以直接解决的复杂问题，分解成两个或更多个相同或相似的、规模更小的子问题，然后**递归**地解决这些子问题，最后将子问题的解合并，得到原问题的解。

### 3.2 分治算法的步骤

分治算法通常包括三个步骤：

1. **分解 (Divide)**：将原问题分解成若干个规模较小、相互独立、与原问题形式相同的子问题。
2. **解决 (Conquer)**：递归地解决这些子问题。如果子问题的规模足够小，可以直接解决。
3. **合并 (Combine)**：将子问题的解合并成原问题的解。

### 3.3 分治算法的应用

**分治算法的典型应用包括：**

- **归并排序 (Merge Sort)**：将数组分成两半，分别排序，然后合并两个有序的半数组。
- **快速排序 (Quick Sort)**：选择一个基准元素，将数组分成两部分（小于基准的和大于基准的），然后递归地排序这两个部分。
- **二分查找 (Binary Search)**：每次将查找范围缩小一半，直到找到目标元素或确定不存在。
- **大整数乘法 (Karatsuba Algorithm)**：将两个大整数的乘法分解成几个较小整数的乘法。
- **汉诺塔 (Towers of Hanoi)**：将N个盘子从一根柱子移动到另一根柱子的问题，可以分解为移动N-1个盘子的问题。

### 3.4 分治算法的优缺点

**优点：**

- **高效性：** 许多分治算法（如归并排序、快速排序）具有较好的时间复杂度，通常为 O(NlogN)。
- **并行性：** 子问题之间通常是独立的，这使得分治算法易于并行化处理。
- **结构清晰：** 算法设计思想直观，代码结构通常比较简洁。

**缺点：**

- **递归开销：** 递归调用会产生额外的函数调用开销，并占用栈空间。如果递归深度过大，可能导致栈溢出。
- **不适用于所有问题：** 并非所有问题都能分解成相互独立的子问题，或者子问题的合并过程过于复杂。
- **重复计算：** 在某些情况下，不同的子问题可能会计算相同的小问题，导致重复计算（例如，朴素的斐波那契数列递归）。这可以通过记忆化或动态规划来解决。



## 4.贪心算法

### 4.1 什么是贪心算法

贪心算法（Greedy Algorithm）是一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是全局最好或最优的算法策略。

它的核心思想是：

1. **做出局部最优选择**：在每一步决策时，都选择当前看起来最好的选项，不考虑未来的后果。
2. **不后悔**：一旦做出选择，就不会再回头修改，因为假设当前的最优选择最终能导向全局最优解。

### 4.2 贪心算法特点

**1.短视性**：它只关注当前局部最优解，不考虑全局情况，也不进行回溯。

**2.简单高效**：通常实现起来比较简单，而且在某些问题上能获得非常高的效率。

**3.不一定能得到全局最优解**：贪心算法的关键在于，它不总是能得到问题的全局最优解。只有当问题满足“贪心选择性质”和“最优子结构性质”时，贪心算法才能保证得到全局最优解。

### 4.3 贪心算法的性质

**贪心选择性质（Greedy Choice Property）**：指的是一个全局最优解可以通过局部最优（贪心）选择来达到。也就是说，每一步的局部最优选择，最终会是全局最优解的一部分。

**最优子结构性质（Optimal Substructure Property）**： 指的是一个问题的最优解包含其子问题的最优解。这与动态规划的定义类似，但贪心算法对子问题的选择是基于局部最优的，而不是通过比较所有子问题的解来构建。

### 4.4 贪心算法应用

**霍夫曼编码（Huffman Coding）**：用于数据压缩，每次选择频率最低的两个节点合并。

**最小生成树算法（Prim's Algorithm, Kruskal's Algorithm）**：用于寻找连接所有顶点的最小总权重的边集。

**活动选择问题（Activity Selection Problem）**：选择在给定时间内尽可能多的不冲突活动。

**找零问题**：在某些货币体系下（如多数国家的硬币系统），用最少数量的硬币凑出给定金额。

## 5.动态规划

### 5.1 什么是动态规划

动态规划（Dynamic Programming，简称 DP）是一种在数学、计算机科学和经济学中使用的，通过把复杂问题分解成更简单的子问题来解决复杂问题的优化技术。它通常适用于那些具有**重叠子问题**和**最优子结构**性质的问题。

### 5.2 核心概念

**重叠子问题（Overlapping Subproblems）：**

- 指的是在解决一个问题的过程中，许多子问题会被重复计算多次。
- 动态规划通过存储这些子问题的解来避免重复计算，通常使用一个表格（数组或多维数组）来保存已经计算过的子问题的结果。当再次需要这些子问题的解时，可以直接从表格中查询，而不是重新计算。
- 示例：计算斐波那契数列 `F(n) = F(n-1) + F(n-2)` 时，计算 `F(5)` 需要 `F(4)` 和 `F(3)`，而计算 `F(4)` 又需要 `F(3)` 和 `F(2)`，`F(3)` 被重复计算了。

**最优子结构（Optimal Substructure）：**

- 指的是一个问题的最优解可以通过其子问题的最优解来构造。
- 如果一个问题的最优解包含其子问题的最优解，那么这个问题就具有最优子结构性质。
- 示例：最短路径问题中，从起点 A 到终点 B 的最短路径，一定包含从 A 到路径上任意中间点 C 的最短路径，以及从 C 到 B 的最短路径。

### 5.3 两种常见实现方式

**自顶向下（Top-Down）/ 记忆化搜索（Memoization）：**

- 这种方法从原问题开始，递归地向下分解子问题，直到遇到基本情况。
- 在计算每个子问题时，会检查其结果是否已经计算并存储过。如果已经存储，就直接返回；如果没有，就计算它并存储结果，以供后续使用。
- 优点：更接近直观的递归定义，只计算实际需要的子问题。
- 缺点：递归调用的开销可能较大。

**自底向上（Bottom-Up）/ 迭代法（Tabulation）：**

- 这种方法从最小的子问题开始，逐步计算并存储它们的结果。
- 然后，使用这些已知的子问题的解来计算更大规模的子问题，直到最终得到原问题的解。
- 优点：通常避免了递归开销，迭代实现更高效。
- 缺点：可能需要计算一些实际上不需要的子问题。

### 5.4 与贪心的区别

贪心算法和动态规划都利用了最优子结构性质。但不同之处在于，动态规划在做出选择时会考虑所有可能的子问题解，并通常填充一张表来避免重复计算；而贪心算法则直接做出一个局部最优选择，不考虑其他可能性，也不进行回溯。因此，贪心算法的适用范围比动态规划小，但当它适用时，通常更高效。



## 6.枚举法

### 6.1 什么是枚举法

**枚举法**，也称为**穷举法**或**列举法**，是一种在解决问题时，将问题所有可能的**解**或**情况**一一列举出来，然后对每一个解或情况进行判断，从而找出符合条件的解的方法。简单来说，就是“一个不漏地把所有可能性都试一遍”。

简单来说：**就是for循环一直试**

### 6.2 何时使用枚举法

枚举法虽然简单直观，但并不是适用于所有问题。它通常在以下情况中比较适用：

- **问题规模较小**：当所有可能的情况数量有限且不大时，枚举法效率较高。如果可能性太多，枚举法可能会非常耗时。
- **解空间可以明确定义**：能够清晰地确定所有可能解的范围和特征。
- **判断条件明确**：有明确的标准来判断一个解是否符合要求。
- **想不到更高效的算法**：在没有更优化、更高效的算法（如数学公式、动态规划、贪心算法等）时，枚举法可以作为一种备选方案。

### 6.3 枚举法的优缺点

**优点**

- **简单直观：**易于理解和实现，不需要复杂的理论知识。
- **准确性高：**如果枚举范围正确且判断条件无误，枚举法通常能找到所有符合条件的解，不会遗漏。

缺点

- **效率低下：**当问题规模较大时，可能的组合数量会呈指数级增长，导致计算量巨大，耗时过长。
- **不适用于大规模问题：**对于计算复杂度高的问题，枚举法几乎不可行。

### 6.4 例子

#### 6.4.1 例一

今有鸡兔同笼，上有三十五头，下有九十四足，问鸡兔各几何?

输入描述

无

输出描述

鸡的数量、兔的数量



输入样例 1

```cpp
无
```

输出样例 1

```cpp
23 12
```

提示

有若干只鸡和兔在同个笼子里，从上面数，有 35 个头；从下面数，有 94只脚。求笼中各有几只鸡和兔



枚举所有可能情况

```cpp
#include<iostream>
using namespace std;
int main()
{
    int i,j;
    //循环鸡可能的范围 
    for(i=1;i<=35;i++)
    {
        //循环兔可能的范围 
        for(j=1;j<=35;j++)
        { 
        if(i+j == 35 && 2*i+4*j == 94) 
            cout<<i<<" "<<j<<endl;
        } 
    }
    return 0; 
}
```

因为循环太多次了

因此需要优化：

```cpp
#include<iostream>
using namespace std;
int main()
{
    int i;
    //循环鸡可能的范围
    for(i=1;i<=35;i++)
    {
        if(i*2+(35-i)*4 == 94)
        {
            cout<<i<<" "<<35-i<<endl;
        }
    }
}
```



#### 6.4.2 例二

今有鸡翁一值钱五，鸡母一值钱三，鸡雏三值钱一。百钱买百鸡，问鸡翁、鸡母、鸡雏各几何？

输入描述

无

输出描述

鸡翁、鸡母、鸡雏的数量



输入样例 1

```cpp
无
```

输出样例 1

```cpp
4 18 78
8 11 81
12 4 84
```

提示

公鸡 55 文钱一只，母鸡 33 文钱一只，小鸡 33 只一文钱，用 100 文钱买一百只鸡，其中公鸡，母鸡，小鸡都必须要有，问公鸡，母鸡，小鸡要买多少只刚好凑足 100 文钱

```cpp
#include<iostream>  
using namespace std;  

int main() {  
    int x, y, z;  // 定义三个整型变量x,y,z，分别表示三种物品的数量
    
    // 第一层循环：枚举第一种物品的数量x，从1到99
    for(x = 1; x < 100; x++) {
        // 第二层循环：枚举第二种物品的数量y，从1到99
        for(y = 1; y < 100; y++) {
            // 第三层循环：枚举第三种物品的数量z，从1到99
            for(z = 1; z < 100; z++) {
                // 检查是否满足以下三个条件：
                // 1. 总价格等于100：5元*x + 3元*y + (1/3)元*z = 100
                // 2. z必须是3的倍数（因为1/3元需要整数价格）
                // 3. 总数量等于100：x + y + z = 100
                if(5*x + 3*y + z/3 == 100 && z % 3 == 0 && x + y + z == 100) {
                    // 如果满足条件，输出x,y,z的值
                    cout << x << " " << y << " " << z << endl;
                }
            }
        }
    }
}
```

优化方法:**减少循环层数 + 数学约束条件**

```cpp
#include<iostream>
using namespace std;

int main() {
    int x, y, z;  // x:第一种物品数量，y:第二种，z:第三种

    // 优化1：x范围收紧（因为5x < 100 ⇒ x <20）
    for(x = 1; x < 20; x++) {
        // 优化2：y范围收紧（因为3y <100 ⇒ y <33）
        for(y = 1; y < 33; y++) {
            // 优化3：直接用公式计算z，省去第三层循环
            z = 100 - x - y;
            
            // 优化4：检查z是3的倍数且总价等于100
            if(z % 3 == 0 && 5*x + 3*y + z/3 == 100) {
                cout << x << " " << y << " " << z << endl;
            }
        }
    }
    return 0;
}
```

## 7.排序法

#### 7.1 冒泡排序

冒泡排序（Bubble Sort）是一种简单直观的排序算法。它的核心思想是重复地遍历待排序的数列，一次比较两个相邻的元素，如果它们的顺序不符合要求，就将它们交换过来。

这个过程就像水里的气泡一样，较小的（或较大的）元素会像气泡一样逐渐“冒”到数列的顶端，因此得名“冒泡排序”。

**算法工作原理**：

假设我们要将一个数组从小到大排序：

1. **第一轮遍历：**
   - 从数组的第一个元素开始，依次比较相邻的两个元素。
   - 如果第一个元素比第二个大，就交换它们的位置。
   - 持续这个过程直到遍历到数组的末尾。
   - 在这一轮结束后，最大的元素会“沉”到数组的最后一个位置。
2. **第二轮遍历：**
   - 再次从数组的第一个元素开始，重复第一轮的比较和交换过程。
   - 但这一次，我们只需要遍历到倒数第二个位置，因为最后一个位置的元素已经是最大的了。
   - 在这一轮结束后，第二大的元素会“沉”到倒数第二个位置。
3. **重复过程：**
   - 重复以上步骤，直到整个数组有序。每一轮遍历，都会将一个未排序的最大元素放到其正确的位置。

**示例**

假设我们有一个数组 `[5, 1, 4, 2, 8]`，我们来演示冒泡排序的过程：

**原始数组：** `[5, 1, 4, 2, 8]`

**第一轮：**

- 比较 `5` 和 `1`，`5 > 1`，交换 → `[1, 5, 4, 2, 8]`
- 比较 `5` 和 `4`，`5 > 4`，交换 → `[1, 4, 5, 2, 8]`
- 比较 `5` 和 `2`，`5 > 2`，交换 → `[1, 4, 2, 5, 8]`
- 比较 `5` 和 `8`，`5 < 8`，不交换 → `[1, 4, 2, 5, 8]` **第一轮结束，最大的元素 `8` 已经到了末尾。**

**第二轮：**

- 比较 `1` 和 `4`，`1 < 4`，不交换 → `[1, 4, 2, 5, 8]`
- 比较 `4` 和 `2`，`4 > 2`，交换 → `[1, 2, 4, 5, 8]`
- 比较 `4` 和 `5`，`4 < 5`，不交换 → `[1, 2, 4, 5, 8]` **第二轮结束，第二大的元素 `5` 已经到了倒数第二个位置。**

**第三轮：**

- 比较 `1` 和 `2`，`1 < 2`，不交换 → `[1, 2, 4, 5, 8]`
- 比较 `2` 和 `4`，`2 < 4`，不交换 → `[1, 2, 4, 5, 8]` **第三轮结束，数组已经有序。**



```cpp
#include <iostream>
using namespace std;

int main()
{
    int n;
    cin >> n;

    int a[1000];

    for (int i = 0; i < n; i++) {
        cin >> a[i];
    }

    // 冒泡排序
    for (int i = 0; i < n - 1; i++) {	// 控制排序的轮数，总共进行 n-1 轮 因为每一轮都把一个最大的值冒到后面，只需要比较 n-1 轮就够了
        for (int j = 0; j < n - 1 - i; j++) {//j < n - 1 - i 是为了 跳过已排好部分，提高效率,因为每轮都会确定一个最大的数放到最后，所以不必再去比较已经排好序的尾部,避免无用比较；若写成 j < n - 1，虽然不影响最终排序结果，但会多比较无意义的部分，效率更低。
            if (a[j] > a[j + 1]) {
                // 交换
                //或者直接swap(a[j],a[j+1]);
                int temp = a[j];
                a[j] = a[j + 1];
                a[j + 1] = temp;
            }
        }
    }

    // 输出排序后的数组
    for (int i = 0; i < n; i++) {
        cout << a[i]<< " ";
    }

    cout << endl;
    return 0;
}

```

**最好时间复杂度：** O(n)

- 当输入数组**已经完全有序**时，冒泡排序只需要进行一次遍历，就会发现没有元素需要交换。此时，它会设置一个标志位并提前终止。它仍然需要遍历所有 n−1 个元素进行比较，但不需要进行任何交换，所以时间复杂度是线性的。

**最坏时间复杂度：** O(n<sup>2</sup>)

- 当输入数组**完全逆序**时，每一轮遍历都需要进行最多的比较和交换操作。外层循环需要 n−1 次，内层循环的比较次数约为 (n−1)+(n−2)+⋯+1=2n(n−1) 次。因此，时间复杂度是平方级的。

**平均时间复杂度：** O(n<sup>2</sup>)

- 在大多数随机输入的数组中，冒泡排序的元素交换和比较次数都近似于最坏情况。平均来看，每个元素都需要与大约一半的其他元素进行比较和潜在的交换，因此平均性能也是平方级的。

#### 7.2 选择排序

选择排序是一种简单直观的排序算法。它的核心思想是在未排序的序列中找到最小（或最大）的元素，然后将其放到排序序列的起始位置。

**算法工作原理**

假设我们要将一个数组从小到大排序：

1. **第一轮遍历：**
   - 从整个待排序的数组中，找到值最小的那个元素。
   - 将它与数组的第一个元素进行交换。
   - 此时，数组的第一个位置就是已排序序列的第一个元素。
2. **第二轮遍历：**
   - 从数组的第二个位置开始（即剩余的未排序部分），找到值最小的那个元素。
   - 将它与数组的第二个元素进行交换。
   - 此时，数组的前两个位置就是已排序序列。
3. **重复过程：**
   - 重复以上步骤，直到所有元素都找到其最终位置。每一轮遍历，都会确定一个元素在最终有序序列中的位置。

这个过程就像在挑选扑克牌，每次从剩下的牌中挑出一张最小的牌，然后放到已排序的牌堆后面。

**示例**

假设我们有一个数组 `[5, 1, 4, 2, 8]`，我们来演示选择排序的过程：

**原始数组：** `[5, 1, 4, 2, 8]`

**第一轮：**

- 遍历整个数组 `[5, 1, 4, 2, 8]`，找到最小的元素是 `1`。
- `1` 应该放在数组的第一个位置，当前第一个元素是 `5`。
- 将 `1` 和 `5` 进行交换。
- 数组变为 `[1, 5, 4, 2, 8]`。 **第一轮结束，`1` 已经确定了其最终位置。**

**第二轮：**

- 从数组的第二个位置开始，遍历未排序部分 `[5, 4, 2, 8]`。
- 找到最小的元素是 `2`。
- `2` 应该放在数组的第二个位置，当前第二个元素是 `5`。
- 将 `2` 和 `5` 进行交换。
- 数组变为 `[1, 2, 4, 5, 8]`。 **第二轮结束，`2` 已经确定了其最终位置。**

**第三轮：**

- 从数组的第三个位置开始，遍历未排序部分 `[4, 5, 8]`。
- 找到最小的元素是 `4`。
- `4` 应该放在数组的第三个位置，当前第三个元素就是 `4`。
- 无需交换。
- 数组仍然是 `[1, 2, 4, 5, 8]`。 **第三轮结束，`4` 已经确定了其最终位置。**

**第四轮：**

- 从数组的第四个位置开始，遍历未排序部分 `[5, 8]`。
- 找到最小的元素是 `5`。
- `5` 已经位于正确的位置，无需交换。
- 数组仍是 `[1, 2, 4, 5, 8]`。 **第四轮结束，数组已经有序。**

```cpp
#include <iostream>

// 自定义交换函数
void swap(int* a, int* b) {
    int temp = *a;
    *a = *b;
    *b = temp;
}

// 选择排序函数
void selectionSort(int arr[], int n) {
    // 外层循环控制已排序元素的数量
    for (int i = 0; i < n - 1; ++i) {
        // 假设当前位置 i 是最小元素的索引
        int min_idx = i;

        // 内层循环在未排序部分寻找最小元素
        for (int j = i + 1; j < n; ++j) {
            // 如果找到比当前 min_idx 处元素更小的
            if (arr[j] < arr[min_idx]) {
                min_idx = j;
            }
        }

        // 将找到的最小元素与当前位置 i 处的元素交换
        // 如果 min_idx 和 i 不相等，才进行交换
        if (min_idx != i) {
            swap(&arr[min_idx], &arr[i]);
        }
    }
}

// 打印数组的函数
void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++) {
        std::cout << arr[i] << " ";
    }
    std::cout << std::endl;
}

int main() {
    int numbers[] = {5, 1, 4, 2, 8};
    int n = sizeof(numbers) / sizeof(numbers[0]);

    std::cout << "Original array: ";
    printArray(numbers, n);

    selectionSort(numbers, n);

    std::cout << "Sorted array:   ";
    printArray(numbers, n);

    return 0;
}
```



**最好时间复杂度：** O(n<sup>2</sup>)

- 选择排序的最好情况和最坏情况**相同**。无论数组是否已排序，它都需要遍历整个未排序部分来寻找最小元素。即使数组已经有序，它也必须完成所有的比较操作来确认这一点。因此，比较次数总是固定的，约为 2n(n−1) 次。

**最坏时间复杂度：** O(n<sup>2</sup>)

- 同上，最坏情况下，比较次数和交换次数与最好情况相同。

**平均时间复杂度：** O(n<sup>2</sup>)

- 选择排序的平均情况和最好、最坏情况都一样。它的主要工作是**比较**，而比较的次数总是固定的，不依赖于输入数组的初始顺序。它总是在未排序部分中搜索最小（或最大）元素，这个过程需要线性时间，并且这个过程需要重复 n−1 次。因此，它的平均时间复杂度也是平方级的。

#### 7.3 插入排序

插入排序是一种非常直观且简单的排序算法，它的工作方式类似于我们整理扑克牌。它的核心思想是**将一个待排序的元素，插入到已经排好序的有序序列中**。

**算法工作原理**

假设我们要将一个数组从小到大排序：

1. **初始状态：**
   - 将数组的第一个元素视为一个已排序的序列。
2. **第一轮遍历：**
   - 取出第二个元素，将其与已排序序列（第一个元素）进行比较。
   - 如果它比已排序序列中的元素小，就将已排序序列中的元素往后移一位，然后将该元素插入到正确的位置。
3. **后续遍历：**
   - 依次取出未排序的元素。
   - 将这个元素与已排序序列从后往前依次比较。
   - 如果已排序序列中的元素比它大，就将该元素往后移动。
   - 直到找到一个比它小的元素，或者到达序列的开头，就将该元素插入到它后面。

**示例**

假设我们有一个数组 `[5, 1, 4, 2, 8]`，我们来演示插入排序的过程：

**原始数组：** `[5, 1, 4, 2, 8]`

- **第 1 步：** 数组的第一个元素 `5` 视为已排序序列 `[5]`。
- **第 2 步：** 取出第二个元素 `1`。
  - 将 `1` 与已排序序列 `[5]` 中的 `5` 比较。
  - `1 < 5`，将 `5` 往后移，然后将 `1` 插入到 `5` 的前面。
  - 数组变为 `[1, 5, 4, 2, 8]`。
- **第 3 步：** 取出第三个元素 `4`。
  - 将 `4` 与已排序序列 `[1, 5]` 中的 `5` 比较。
  - `4 < 5`，将 `5` 往后移。
  - 再将 `4` 与 `1` 比较。`4 > 1`，将 `4` 插入到 `1` 的后面。
  - 数组变为 `[1, 4, 5, 2, 8]`。
- **第 4 步：** 取出第四个元素 `2`。
  - 将 `2` 与已排序序列 `[1, 4, 5]` 中的 `5` 比较，`2 < 5`，`5` 后移。
  - 再与 `4` 比较，`2 < 4`，`4` 后移。
  - 再与 `1` 比较，`2 > 1`，将 `2` 插入到 `1` 的后面。
  - 数组变为 `[1, 2, 4, 5, 8]`。
- **第 5 步：** 取出第五个元素 `8`。
  - 将 `8` 与已排序序列 `[1, 2, 4, 5]` 中的 `5` 比较。
  - `8 > 5`，无需移动，将 `8` 插入到 `5` 的后面。
  - 数组变为 `[1, 2, 4, 5, 8]`。 **所有元素都已插入，排序完成。**



```cpp
#include <iostream>

// 插入排序函数
void insertionSort(int arr[], int n) {
    // 从第二个元素开始遍历，将每个元素插入到已排序部分
    for (int i = 1; i < n; ++i) {
        // key 是当前要插入的元素
        int key = arr[i];
        // j 是已排序部分的最后一个元素的索引
        int j = i - 1;

        // 循环移动已排序部分中比 key 大的元素，为 key 腾出位置
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j]; // 将元素后移一位
            j = j - 1;           // 比较前一个元素
        }

        // 找到合适的位置后，将 key 插入
        arr[j + 1] = key;
    }
}

// 打印数组的函数
void printArray(int arr[], int size) {
    for (int i = 0; i < size; i++) {
        std::cout << arr[i] << " ";
    }
    std::cout << std::endl;
}

int main() {
    int numbers[] = {5, 1, 4, 2, 8};
    int n = sizeof(numbers) / sizeof(numbers[0]);

    std::cout << "Original array: ";
    printArray(numbers, n);

    insertionSort(numbers, n);

    std::cout << "Sorted array:   ";
    printArray(numbers, n);

    return 0;
}
```



**最好时间复杂度：** O(n)

- 当输入数组**已经完全有序**时，插入排序在遍历每个元素时，只需要将其与它前面的元素进行一次比较，就会发现它已经在正确的位置上，不需要再进行移动。所以，比较次数是线性的，总时间复杂度是线性的。

**最坏时间复杂度：** O(n<sup>2</sup>)

- 当输入数组**完全逆序**时，每个元素在插入时都需要与前面所有已排序的元素进行比较和移动。例如，第二个元素需要比较 1 次，第三个需要比较 2 次，第 n 个需要比较 n−1 次。总的比较和移动次数约为 (1+2+⋯+(n−1))=2n(n−1) 次。因此，时间复杂度是平方级的。

**平均时间复杂度：** O(n<sup>2</sup>)

- 在随机输入的数组中，一个元素需要插入到已排序部分的正确位置，平均来说，这个位置大约在中间。这意味着每个元素平均需要与大约一半的已排序元素进行比较和移动。因此，总的比较和移动次数也是平方级的。

| 算法         | 最好时间复杂度   | 最坏时间复杂度   | **平均时间复杂度**   | 稳定性 |
| ------------ | ---------------- | ---------------- | -------------------- | ------ |
| **冒泡排序** | O(n)             | O(n<sup>2</sup>) | O(n<sup>2</sup>) | 稳定   |
| **选择排序** | O(n<sup>2</sup>) | O(n<sup>2</sup>) | O(n<sup>2</sup>) | 不稳定 |
| **插入排序** | O(n)             | O(n<sup>2</sup>) | O(n<sup>2</sup>) | 稳定   |

## 8.递推算法

递推算法是一种通过**已知的简单条件和相邻项之间的关系**，逐步推导出问题的最终解的算法。它将一个复杂问题分解为一系列相互关联的子问题，然后按照一定的顺序，从最简单的子问题开始，逐步解决，直到达到最终目标。

递推的核心是**递推关系式（Recurrence Relation）**，它定义了如何从一个或多个已知的项来计算下一个项。

**递推算法的基本思想**

递推算法的基本思想可以概括为以下几点：

1. **确定递推关系式**：找出问题中当前项与前一项（或前几项）之间的数学关系。这个关系式是递推算法的灵魂。
2. **确定边界条件**：找到递推过程的起点，也就是最简单、可以直接求出解的子问题。这些边界条件（或初始值）是递推的基石。
3. **按顺序计算**：从边界条件开始，按照递推关系式，一步步地向前计算，直到达到需要求解的目标项。

**递推与递归（Recursion）的区别：**

- **递推**是**自底向上**的。它从已知的初始值开始，逐步推导到最终结果。
- **递归**是**自顶向下**的。它将一个大问题分解为与自身相同的小问题，直到达到边界条件，然后从边界条件向上返回，逐层计算最终结果。
- 通常，递推算法的效率更高，因为它避免了递归带来的函数调用栈开销。但有时候，递归的表达方式更自然、更直观。



**示例 ：斐波那契数列**

- **问题**：求斐波那契数列的第 n 项。数列定义为：f(0)=0,f(1)=1，从第三项开始，每一项都是前两项之和。
- **分析**：
  - **边界条件**：我们知道前两项的值是固定的：f(0)=0,f(1)=1。
  - **关系**：每一项都是前两项之和。
- **递推关系式**： f(n)=f(n−1)+f(n−2)
- **递推实现**：
  - 从 f(0) 和 f(1) 开始。
  - 计算 f(2)=f(1)+f(0)=1+0=1。
  - 计算 f(3)=f(2)+f(1)=1+1=2。
  - ... 如此类推，直到求出 f(n)。

```cpp
#include <iostream>

int main() {
    // 要计算的斐波那契数列的项数
    int n = 10;

    // 边界条件：n <= 1
    if (n <= 1) {
        std::cout << "斐波那契数列的第 " << n << " 项是: " << n << std::endl;
        return 0;
    }

    // 只需两个变量来存储前两项的值
    long long prev1 = 1; // 存储 f(i-1)
    long long prev2 = 0; // 存储 f(i-2)
    long long current = 0; // 存储 f(i)

    // 从 i=2 开始计算，直到 n
    for (int i = 2; i <= n; ++i) {
        // 递推关系式：当前项 = 前一项 + 前两项
        current = prev1 + prev2;

        // 更新变量以准备计算下一项
        prev2 = prev1;
        prev1 = current;
    }

    std::cout << "斐波那契数列的第 " << n << " 项是: " << current << std::endl;

    return 0;
}
```

## 9. 递归算法

递归算法是一种通过调用自身来解决问题的算法。它将一个复杂的问题分解成一个或多个与原始问题相同但规模更小的子问题，直到这些子问题足够简单可以直接解决。

#### 9.1 递归的两个核心要素

一个有效的递归算法必须包含两个基本部分：

1. **递归基（Base Case）**：这是递归的终止条件。它是一个足够简单的问题，可以直接给出答案，而不需要再进行任何递归调用。如果没有终止条件，递归就会无限地调用下去，导致程序崩溃（栈溢出）。
2. **递归步骤（Recursive Step）**：这是算法的核心部分。它将一个复杂问题分解成一个或多个规模更小的子问题，并**调用自身**来解决这些子问题。每一步递归都应朝着递归基的方向前进。

**一个简单的比喻**

我们可以用“俄罗斯套娃”来比喻递归。

- **大套娃** 代表**原始问题**。
- 打开大套娃，你会发现里面还有一个**小一号的套娃**，这代表**子问题**。
- 你继续打开这个小套娃，直到你找到**最小的、不能再打开的套娃**。这个最小的套娃就是**递归基**。
- 当你找到最小的套娃后，你就可以开始一层层地往回**组装**，最终解决整个问题。

**递归的优点与缺点**

**优点**

- **代码简洁**：对于某些问题，递归的实现方式比循环更清晰、更简洁，尤其适合处理树形结构、图结构等问题。
- **逻辑清晰**：它能自然地表示一些本身就是递归定义的问题，如树的遍历、阶乘计算等。

**缺点**

- **性能开销**：每一次函数调用都会占用一定的内存（栈空间），如果递归深度过大，可能会导致栈溢出。
- **效率低下**：某些递归算法，如斐波那契数列的朴素实现，会进行大量的重复计算，效率远低于迭代（循环）实现。

因此，在编写递归算法时，需要仔细考虑其终止条件和性能问题。



**一个简单的例子：阶乘**

计算一个数的阶乘（`n!`）是理解递归的经典例子。

- **阶乘的定义**：`n! = n * (n-1) * (n-2) * ... * 1`。
- **递归思维**：我们可以把 `n!` 看作是 `n` 乘以 `(n-1)!`。

因此，它的递归算法可以这样设计：

- **递归基**：当 `n` 等于 `0` 时，`0!` 等于 `1`。
- **递归步骤**：`n!` 等于 `n` 乘以 `(n-1)!`。

```cpp
int factorial(int n)
{
    // 递归基：当n为0时，返回1
    if (n == 0)
    {
        return 1;
    }
    // 递归步骤：返回 n * (n-1)!
    else
    {
        return n * factorial(n - 1);
    }
}
```

当计算 `factorial(4)` 时，它的调用过程是这样的： 

`factorial(4)`

 -> `4 * factorial(3)`

 -> `3 * factorial(2)`

 -> `2 * factorial(1)` 

-> `1 * factorial(0)`

 -> 返回 `1`

 -> 返回 `1 * 1 = 1` 

-> 返回 `2 * 1 = 2` 

-> 返回 `3 * 2 = 6` 

-> 返回 `4 * 6 = 24`

#### 9.2 字符串反转

**问题描述**

编写一个递归函数，将输入的字符串反转。

**提示**

- **递归基**：当字符串为空或只有一个字符时，反转后的字符串就是它本身。
- **递归步骤**：将字符串的**第一个字符**移到最后，然后对**剩余的子字符串**进行反转。

**示例**

- 输入：`"hello"`
- 输出：`"olleh"`

```cpp
#include <iostream>
#include <string>

void reverseString(std::string& str, int start, int end)
{
    // 递归终止条件
    if (start >= end)
    {
        return;
    }
    
    // 交换首尾字符
    char temp = str[start];
    str[start] = str[end];
    str[end] = temp;
    
    // 递归调用，处理剩余的子字符串
    reverseString(str, start + 1, end - 1);
}

int main()
{
    std::string myString = "hello";
    reverseString(myString, 0, myString.length() - 1);
    std::cout << "The reversed string is: " << myString << std::endl;
    return 0;
}
```

这段代码的核心是一个名为 `reverseString` 的**递归函数**。它通过不断地交换字符串的首尾字符，并将问题缩小到中间的子字符串，最终实现整个字符串的反转。`main` 函数负责调用这个递归函数，并传入整个字符串及其起始和结束索引。

**递归函数 `reverseString`**

这个函数接收三个参数：

- `std::string& str`: 一个对字符串的**引用**，这意味着函数可以直接修改原始字符串。
- `int start`: 子字符串的起始索引。
- `int end`: 子字符串的结束索引。

**1. 递归终止条件**

```cpp
if (start >= end)
{
    return;
}
```

这是递归的**关键**。当 `start` 索引（从左往右走）变得大于或等于 `end` 索引（从右往左走）时，说明整个字符串已经被完整地交换或子字符串只剩下一个字符（或为空）。此时，递归不再继续，函数直接返回，从而**结束**了层层深入的调用。

**2. 交换首尾字符**

```cpp
char temp = str[start];
str[start] = str[end];
str[end] = temp;
```

这一步是每次递归调用的核心操作。它使用一个临时变量 `temp` 来**交换**当前子字符串的首字符 (`str[start]`) 和尾字符 (`str[end]`)。例如，对于 `"hello"`, 第一次调用会交换 `h` 和 `o`。

**3. 递归调用**

```cpp
reverseString(str, start + 1, end - 1);
```

在交换完首尾字符之后，函数会**再次调用自身**，但这次是针对一个**更小的子字符串**。新的起始索引 `start + 1` 向右移动了一位，新的结束索引 `end - 1` 向左移动了一位。这样，问题就被分解成一个更简单的子问题，直到满足终止条件。

## 10.算法复杂度

算法复杂度是衡量算法运行时间或所需空间随输入规模增长而增长的趋势。我们通常使用**大O符号（Big O notation）**来表示。

### 10.1 算法复杂度估算的基本原则

- **只关注主导项**：当 n 趋于无穷大时，我们只保留增长最快的项，并忽略其系数和低阶项。
  - 例如：O(2n<sup>2</sup>+100n+500) 简化为 O(n<sup>2</sup>)。
- **循环是关键**：循环是决定时间复杂度的最主要因素。
  - **单层循环**：通常是线性的，时间复杂度为 O(n)。
  - **嵌套循环**：通常是多项式的，时间复杂度为 O(n<sup>k</sup>)，其中 k 是嵌套的层数。

### 10.2 多项式复杂度

多项式复杂度是算法性能比较好的类别，它的运行时间是输入规模 n 的多项式函数。

**示例 1: 线性复杂度 O(n)**

- **特点**：算法的运行时间与输入规模 n 成正比。

- **代码特征**：通常由**一层循环**构成，循环次数与 n 成正比。

- **估算**：

  - 假设一个数组有 n 个元素。
  - 下面的代码只遍历数组一次：

  ```cpp
  void printArray(int arr[], int n) {
      for (int i = 0; i < n; i++) {
          // 这段代码执行了 n 次
          std::cout << arr[i];
      }
  }
  ```

  - 循环执行了 n 次，所以时间复杂度是 O(n)。

**示例 2: 平方复杂度 O(n<sup>2</sup>)**

- **特点**：算法的运行时间与输入规模 n 的平方成正比。

- **代码特征**：通常由**两层嵌套循环**构成。

- **估算**：

  - 以选择排序为例：

  ```cpp
  void selectionSort(int arr[], int n) {
      for (int i = 0; i < n - 1; i++) {       // 外层循环：执行了 n-1 次
          for (int j = i + 1; j < n; j++) {   // 内层循环：执行了大约 n/2 次
              if (arr[j] < arr[min_idx]) {
                  min_idx = j;
              }
          }
      }
  }
  ```

  - 外层循环执行了 n−1 次。
  - 内层循环在第一次外层循环时执行了 n−1 次，在第二次时执行了 n−2 次，...，直到最后执行 1 次。
  - 总的执行次数约为 (n−1)+(n−2)+…..+1=n(n−1)/2，这是一个 n<sup>2</sup> 的多项式。
  - 根据只关注主导项的原则，时间复杂度是 O(n<sup>2</sup>)。

**示例 3: 对数复杂度 O(logn)**

- **特点**：算法的运行时间随 n 的增长而增长得非常缓慢。

- **代码特征**：通常是**“分而治之”**的算法，每次操作都将问题规模减半。

- **估算**：

  - 以二分查找为例：

  ```cpp
  int binarySearch(int arr[], int n, int x) {
      int low = 0, high = n - 1;
      while (low <= high) {
          int mid = (low + high) / 2;
          if (arr[mid] == x) return mid;
          else if (arr[mid] < x) low = mid + 1;
          else high = mid - 1;
      }
      return -1;
  }
  ```

  - 在每次循环中，查找的范围 `high - low` 都被缩小一半。
  - 问题规模从 n..n/2….n/4….1。
  - 假设循环执行了 k 次，那么 n*(1/2)<sup>k</sup>=1，所以 n=2<sup>k</sup>。
  - 对两边取对数，得到 k=log_2n。
  - 所以时间复杂度是 O(logn)。

### 10.3 指数复杂度

指数复杂度是算法性能最差的类别之一，它的运行时间与 2<sup>n</sup> 或 c<sup>n</sup> 成正比。这类算法在 n 稍微增大时，运行时间会呈爆炸式增长，通常只适用于非常小的输入规模。

**示例: 指数复杂度 O(2<sup>n</sup>)**

- **特点**：算法的运行时间随 n 的增长呈指数级增长。

- **代码特征**：通常是**递归**算法，且每个函数调用都产生**多个**（通常是两个或更多）子调用，且没有有效的记忆化或剪枝。

- **估算**：

  - 以没有优化的递归斐波那契数列为例：

  ```cpp
  int fibonacci(int n) {
      if (n <= 1) return n;
      return fibonacci(n - 1) + fibonacci(n - 2);
  }
  ```

  - 为了计算 `fibonacci(n)`，需要计算 `fibonacci(n-1)` 和 `fibonacci(n-2)`。
  - 为了计算 `fibonacci(n-1)`，又需要计算 `fibonacci(n-2)` 和 `fibonacci(n-3)`。
  - 这会形成一个二叉树状的递归调用，且有大量的重复计算。
  - 递归树的深度是 n，但叶子节点的数量是 2<sup>n</sup> 级别的。
  - 所以，它的时间复杂度是 O(2<sup>n</sup>)。

**总结**

- **多项式复杂度**：通常是“好”的算法。
  - O(logn)：非常快，通常通过分治法实现。
  - O(n)：线性，非常高效。
  - O(nlogn)：高效，是许多高级排序算法（如快速排序、归并排序）的复杂度。
  - O(n<sup>2</sup>)：可以接受，但效率不高，常见于简单的排序算法。
  - O(n<sup>k</sup>)：通常在 k 较小时可行。
- **指数复杂度**：通常是“坏”的算法。
  - O(2<sup>n</sup>)：运行时间随 n 呈爆炸式增长，只适用于极小规模的问题。

简单估算时，只需要数清楚代码中**循环嵌套的层数**（多项式），或者**递归调用产生的子问题数量**（指数）。
